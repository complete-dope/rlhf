{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9ee0912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification , AutoModelForCausalLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adcbd2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mohitdulani/Desktop/personal/rlhf'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "FILE_PATH = os.path.dirname(os.path.abspath(\"\"))\n",
    "FILE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa752d2",
   "metadata": {},
   "source": [
    "### Visualise causal LM weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df037dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "BASE_MODEL = \"google/gemma-2b-it\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, cache_dir = FILE_PATH)\n",
    "lm_model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, cache_dir = FILE_PATH)\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "\tmessages,\n",
    "\tadd_generation_prompt=True,\n",
    "\ttokenize=True,\n",
    "\treturn_dict=True,\n",
    "\treturn_tensors=\"pt\",\n",
    ").to(lm_model.device)\n",
    "\n",
    "# outputs = model.generate(**inputs, max_new_tokens=40)\n",
    "# print(tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0b3be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(lm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9942faa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in lm_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in lm_model.lm_head.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# lm_model.state_dict().items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771073de",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95586cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_model.lm_head.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a42136",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa= inputs.get('input_ids') \n",
    "print(aa.size())\n",
    "torch.cat([aa , torch.Tensor(data=[[32]])], dim =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09edcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "outs = []\n",
    "\n",
    "inps = inputs.get('input_ids')\n",
    "for _ in range(100):\n",
    "    out_toks = lm_model.model.embed_tokens(inps)\n",
    "    print(out_toks.shape)\n",
    "    # model_in = lm_model.model.layers(out_toks)\n",
    "\n",
    "    hidden = out_toks\n",
    "    for layer in lm_model.model.layers: \n",
    "        print('inside list')\n",
    "        hidden = layer(hidden)\n",
    "        print(\"hidden is \", hidden)\n",
    "        hidden = hidden[0]\n",
    "\n",
    "    out_linear = lm_model.lm_head(hidden)\n",
    "    print(out_linear.shape)\n",
    "    findmax = torch.argmax(out_linear, dim=-1)\n",
    "    add_back = findmax[:,-1].item()\n",
    "    outs.append(add_back)\n",
    "    print(add_back)\n",
    "    print(inps)\n",
    "    print(type(inps))\n",
    "    inps = torch.cat([inps, torch.tensor([[add_back]], dtype=inps.dtype)], dim=1)\n",
    "\n",
    "outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1293e9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "findmax = torch.argmax(out_linear, dim=-1)\n",
    "findmax[:,-1].item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d02951",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = tokenizer.batch_decode(findmax, skip_special_tokens=True)\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862a5d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_layer = lm_model.model(inputs.get('input_ids'))\n",
    "out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e219be",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_layer.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2b53b8",
   "metadata": {},
   "source": [
    "### Visualise sequence classification model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121fa81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "BASE_MODEL = \"google/gemma-2b-it\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, cache_dir = FILE_PATH)\n",
    "seq_model = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL, cache_dir = FILE_PATH, num_labels = 5)\n",
    "\n",
    "text = \"I am cool\"\n",
    "\n",
    "# Tokenize (no chat template needed)\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(seq_model.device)\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = seq_model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    pred_class = torch.argmax(probs, dim=-1).item()\n",
    "\n",
    "print(\"Probabilities:\", probs)\n",
    "print(\"Predicted class:\", pred_class)\n",
    "\n",
    "# outputs = model.generate(**inputs, max_new_tokens=40)\n",
    "# print(tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8750ef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(seq_model) , seq_model.__class__, seq_model.generation_config , seq_model.from_pretrained, seq_model.forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e991ceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = \"this was a terrific movie  \"\n",
    "\n",
    "\n",
    "# Tokenize (no chat template needed)\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(seq_model.device)\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = seq_model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    pred_class = torch.argmax(probs, dim=-1).item()\n",
    "\n",
    "print(\"Probabilities:\", probs)\n",
    "print(\"Predicted class:\", pred_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5e6d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30251212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebe5f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_model.state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410ab3a0",
   "metadata": {},
   "source": [
    "### Visualizing configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62beadef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "BASE_MODEL = \"google/gemma-2b-it\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(BASE_MODEL) \n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b876591b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60c483c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5598313e",
   "metadata": {},
   "source": [
    "### Using the converted model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e4b1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from conversion import ConvertedModel\n",
    "conv_model = ConvertedModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed411ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use trainer class /  reward model in this \n",
    "from transformers import HfArgumentParser\n",
    "from datasets import load_dataset\n",
    "from conversion import ConvertedModel\n",
    "conv_model = ConvertedModel()\n",
    "from trl import (\n",
    "    ModelConfig,\n",
    "    RewardConfig,\n",
    "    RewardTrainer,\n",
    "    ScriptArguments,\n",
    "    get_kbit_device_map,\n",
    "    get_peft_config,\n",
    "    get_quantization_config,\n",
    "    setup_chat_format,\n",
    ")\n",
    "\n",
    "\n",
    "# parser = HfArgumentParser((ScriptArguments, RewardConfig, ModelConfig))\n",
    "# script_args, training_args, model_args = parser.parse_args_into_dataclasses(args = [])\n",
    "# training_args.gradient_checkpointing_kwargs = dict(use_reentrant=False)\n",
    "\n",
    "dataset = load_dataset(path ='Dahoas/rm-static', cache_dir = FILE_PATH)\n",
    "\n",
    "# trainer = RewardTrainer(\n",
    "#     model=conv_model,\n",
    "#     processing_class=tokenizer,\n",
    "#     train_dataset=dataset\n",
    "# )\n",
    "\n",
    "\n",
    "reward_args = RewardConfig(\n",
    "    output_dir=FILE_PATH,\n",
    "    per_device_train_batch_size=2,\n",
    "    num_train_epochs=1,\n",
    ")\n",
    "\n",
    "trainer = RewardTrainer(\n",
    "    model=conv_model,\n",
    "    processing_class=tokenizer,\n",
    "    args=reward_args,\n",
    "    # train_dataset=dataset[script_args.dataset_train_split],\n",
    "    # eval_dataset=dataset[script_args.dataset_test_split] if training_args.eval_strategy != \"no\" else None,\n",
    "    \n",
    "    # peft_config=get_peft_config(model_args),\n",
    "\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f43072",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoConfig\n",
    "from conversion import ConvertedModel\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"google/gemma-3-270m-it\", num_labels=1, cache_dir = FILE_PATH)\n",
    "\n",
    "print(\"config is \", config)\n",
    "\n",
    "conv_model = ConvertedModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9215e396",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedModel, AutoConfig, AutoModelForCausalLM\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConvertedModel2(PreTrainedModel):\n",
    "    def __init__(self, config, model_name=\"google/gemma-3-270m-it\", num_labels=1, **kwargs):\n",
    "        super().__init__(config)\n",
    "        self.model_name = model_name\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "        self.lm_model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir= FILE_PATH)\n",
    "        for p in self.lm_model.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        logits_count = self.lm_model.lm_head.in_features\n",
    "        self.lm_model.lm_head = nn.Linear(logits_count, num_labels)\n",
    "        # self.classifier = self.lm_model.lm_head\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None, **kwargs):\n",
    "        outputs = self.lm_model.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden = outputs.last_hidden_state\n",
    "        pooled = last_hidden[:, -1, :]\n",
    "        # logits = self.classifier(pooled)\n",
    "        logits = self.lm_model.lm_head(pooled)\n",
    "\n",
    "        return {\"logits\": logits}\n",
    "\n",
    "# usage\n",
    "from transformers import AutoConfig\n",
    "config = AutoConfig.from_pretrained(\"google/gemma-3-270m-it\")\n",
    "conv_model = ConvertedModel2(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a203be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dec83d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15ed219",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"rlhf-reward-model\",\n",
    "    name=\"gemma_linear_head\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bce9e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use trainer class /  reward model in this \n",
    "from transformers import HfArgumentParser\n",
    "from datasets import load_dataset\n",
    "# from conversion import ConvertedModel\n",
    "# conv_model = ConvertedModel()\n",
    "from trl import (\n",
    "    ModelConfig,\n",
    "    RewardConfig,\n",
    "    RewardTrainer,\n",
    "    ScriptArguments,\n",
    "    get_kbit_device_map,\n",
    "    get_peft_config,\n",
    "    get_quantization_config,\n",
    "    setup_chat_format,\n",
    ")\n",
    "\n",
    "\n",
    "dataset = load_dataset(path ='Dahoas/rm-static', cache_dir = FILE_PATH)\n",
    "\n",
    "# reward_args = RewardConfig(\n",
    "#     output_dir=FILE_PATH,\n",
    "#     do_train = True,\n",
    "#     do_eval = True,  \n",
    "#     per_device_train_batch_size=2,\n",
    "#     num_train_epochs=1,\n",
    "#     logging_steps = 10, \n",
    "# )\n",
    "\n",
    "\n",
    "reward_args = RewardConfig(\n",
    "    output_dir=os.path.join(FILE_PATH, \"reward_outputs\"),   # checkpoint + logs dir\n",
    "    logging_dir=os.path.join(FILE_PATH, \"logs\"),            # local tensorboard logs\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=2,\n",
    "    num_train_epochs=10,\n",
    "    logging_steps=10,\n",
    "    gradient_checkpointing=False, \n",
    "\n",
    "    # Precision\n",
    "    fp16=False,          # disable mixed precision\n",
    "    bf16=False,\n",
    "\n",
    "    # Checkpoint saving\n",
    "    save_strategy=\"steps\",   # instead of \"epoch\"\n",
    "    save_steps=5,            # save every 5 steps\n",
    "    save_total_limit=2,      # keep only last 2 checkpoints\n",
    "\n",
    "    # W&B integration\n",
    "    report_to=[],       # logs training metrics to wandb\n",
    "    run_name=\"reward_model_gemma_linear_head\"  # nice display name in wandb\n",
    ")\n",
    "\n",
    "trainer = RewardTrainer(\n",
    "    model=conv_model,\n",
    "    processing_class=tokenizer,\n",
    "    args=reward_args,\n",
    "    train_dataset=dataset['train'], \n",
    "    eval_dataset = dataset['test'],\n",
    "\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8d3ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['test'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314b5b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from conversion import ConvertedModel\n",
    "from transformers import AutoConfig\n",
    "import inspect\n",
    "config = AutoConfig.from_pretrained(\"google/gemma-3-270m-it\")\n",
    "print(inspect.signature(ConvertedModel.__init__))\n",
    "conv_model = ConvertedModel(config)\n",
    "\n",
    "conv_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2539e2",
   "metadata": {},
   "source": [
    "#### Training a reward modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f51fef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from accelerate import logging\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, HfArgumentParser\n",
    "\n",
    "from trl import (\n",
    "    ModelConfig,\n",
    "    RewardConfig,\n",
    "    RewardTrainer,\n",
    "    ScriptArguments,\n",
    "    get_kbit_device_map,\n",
    "    get_peft_config,\n",
    "    get_quantization_config,\n",
    "    setup_chat_format,\n",
    ")\n",
    "\n",
    "\n",
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "# Enable logging in a Hugging Face Space\n",
    "os.environ.setdefault(\"TRACKIO_SPACE_ID\", \"trl-trackio\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = HfArgumentParser((ScriptArguments, RewardConfig, ModelConfig))\n",
    "    script_args, training_args, model_args = parser.parse_args_into_dataclasses()\n",
    "    training_args.gradient_checkpointing_kwargs = dict(use_reentrant=False)\n",
    "\n",
    "    ################\n",
    "    # Model & Tokenizer\n",
    "    ################\n",
    "    torch_dtype = (\n",
    "        model_args.torch_dtype if model_args.torch_dtype in [\"auto\", None] else getattr(torch, model_args.torch_dtype)\n",
    "    )\n",
    "    quantization_config = get_quantization_config(model_args)\n",
    "    model_kwargs = dict(\n",
    "        revision=model_args.model_revision,\n",
    "        device_map=get_kbit_device_map() if quantization_config is not None else None,\n",
    "        quantization_config=quantization_config,\n",
    "        use_cache=False if training_args.gradient_checkpointing else True,\n",
    "        torch_dtype=torch_dtype,\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_args.model_name_or_path, trust_remote_code=model_args.trust_remote_code, use_fast=True\n",
    "    )\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_args.model_name_or_path, num_labels=1, trust_remote_code=model_args.trust_remote_code, **model_kwargs\n",
    "    )\n",
    "    # Align padding tokens between tokenizer and model\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "    # If post-training a base model, use ChatML as the default template\n",
    "    if tokenizer.chat_template is None:\n",
    "        model, tokenizer = setup_chat_format(model, tokenizer)\n",
    "\n",
    "    if model_args.use_peft and model_args.lora_task_type != \"SEQ_CLS\":\n",
    "        logger.warning(\n",
    "            \"You are using a `task_type` that is different than `SEQ_CLS` for PEFT. This will lead to silent bugs\"\n",
    "            \" Make sure to pass --lora_task_type SEQ_CLS when using this script with PEFT.\",\n",
    "        )\n",
    "\n",
    "    ##############\n",
    "    # Load dataset\n",
    "    ##############\n",
    "    dataset = load_dataset(script_args.dataset_name, name=script_args.dataset_config)\n",
    "\n",
    "    ##########\n",
    "    # Training\n",
    "    ##########\n",
    "    trainer = RewardTrainer(\n",
    "        model=model,\n",
    "        processing_class=tokenizer,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset[script_args.dataset_train_split],\n",
    "        eval_dataset=dataset[script_args.dataset_test_split] if training_args.eval_strategy != \"no\" else None,\n",
    "        peft_config=get_peft_config(model_args),\n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "    ############################\n",
    "    # Save model and push to Hub\n",
    "    ############################\n",
    "    trainer.save_model(training_args.output_dir)\n",
    "\n",
    "    if training_args.eval_strategy != \"no\":\n",
    "        metrics = trainer.evaluate()\n",
    "        trainer.log_metrics(\"eval\", metrics)\n",
    "        trainer.save_metrics(\"eval\", metrics)\n",
    "\n",
    "    # Save and push to hub\n",
    "    trainer.save_model(training_args.output_dir)\n",
    "    if training_args.push_to_hub:\n",
    "        trainer.push_to_hub(dataset_name=script_args.dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930577d0",
   "metadata": {},
   "source": [
    "## Training the model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9663da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "\n",
    "BASE_MODEL = \"google/gemma-3-270m-it\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, cache_dir = FILE_PATH)\n",
    "lm_model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, cache_dir = FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992d57cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this files helps to convert the model from causal to sequence modelling part \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "import os\n",
    "from transformers import AutoModelForSequenceClassification, AutoModelForCausalLM, PreTrainedModel\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "# take the base class as pretrained model \n",
    "class ConvertedModel(PreTrainedModel):\n",
    "    def __init__(self, config, **kwargs):\n",
    "        super().__init__(config)\n",
    "        num_labels = kwargs.get('num_labels', 1)\n",
    "        model = kwargs.get('model', \"google/gemma-3-270m-it\")\n",
    "        self.model_name = model\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "        self.FILE_PATH = FILE_PATH\n",
    "\n",
    "        # Device selection (MPS > CUDA > CPU)\n",
    "        if torch.backends.mps.is_available():\n",
    "            self.device_str = 'mps'\n",
    "        elif torch.cuda.is_available():\n",
    "            self.device_str = 'cuda'\n",
    "        else:\n",
    "            self.device_str = 'cpu'\n",
    "\n",
    "        # Load the base CausalLM model\n",
    "        self.lm_model = AutoModelForCausalLM.from_pretrained(self.model_name, cache_dir=self.FILE_PATH)\n",
    "        for params in self.lm_model.parameters():\n",
    "            params.requires_grad = False\n",
    "\n",
    "        # Replace the language modeling head with a classification head\n",
    "        logits_count = self.lm_model.lm_head.in_features\n",
    "        self.lm_model.lm_head = nn.Linear(\n",
    "            in_features=logits_count,\n",
    "            out_features=self.num_labels,\n",
    "            bias=True,\n",
    "            device=self.device_str\n",
    "        )\n",
    "        for params in self.lm_model.lm_head.parameters():\n",
    "            params.requires_grad = True\n",
    "\n",
    "\n",
    "\n",
    "    # def forward(self, input_ids, attention_mask=None):\n",
    "    #     # Get hidden states from the base model\n",
    "    #     outputs = self.lm_model.model(\n",
    "    #         input_ids=input_ids,\n",
    "    #         attention_mask=attention_mask,\n",
    "    #         output_hidden_states=False\n",
    "    #     )\n",
    "\n",
    "    #     # Take last token representation for classification\n",
    "    #     last_hidden = outputs.last_hidden_state  # [batch, seq_len, hidden_dim]\n",
    "    #     pooled = last_hidden[:, -1, :]  # last token\n",
    "\n",
    "    #     # Classify using the replaced head\n",
    "    #     logits = self.lm_model.lm_head(pooled)\n",
    "    #     return {\"logits\": logits}\n",
    "\n",
    "\n",
    "\n",
    "    # def forward(\n",
    "    #     self,\n",
    "    #     input_ids=None,\n",
    "    #     attention_mask=None,\n",
    "    #     labels=None,\n",
    "    #     return_dict=True,\n",
    "    #     **kwargs\n",
    "    # ):\n",
    "    #     # Hidden states\n",
    "    #     outputs = self.lm_model.model(\n",
    "    #         input_ids=input_ids,\n",
    "    #         attention_mask=attention_mask,\n",
    "    #         output_hidden_states=False\n",
    "    #     )\n",
    "\n",
    "    #     # Last hidden state\n",
    "    #     last_hidden = outputs.last_hidden_state  # [batch, seq_len, hidden_dim]\n",
    "    #     pooled = last_hidden[:, -1, :]  # last token\n",
    "\n",
    "    #     # Classification head\n",
    "    #     logits = self.lm_model.lm_head(pooled)\n",
    "\n",
    "    #     loss = None\n",
    "    #     if labels is not None:\n",
    "    #         loss_fn = nn.CrossEntropyLoss()\n",
    "    #         loss = loss_fn(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "    #     if not return_dict:\n",
    "    #         return (logits,) if loss is None else (loss, logits)\n",
    "\n",
    "    #     print('the loss and logits are' ,loss , logits)\n",
    "\n",
    "    #     return {\"loss\": loss, \"logits\": logits}\n",
    "\n",
    "    def forward(self,  input_ids=None, attention_mask=None, labels = None, return_dict =True,**kwargs):\n",
    "        lm_out = self.lm_model.model(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
    "        last_hidden = lm_out.last_hidden_state         # [B, L, H]\n",
    "        pooled = last_hidden[:, -1, :]                 # [B, H]\n",
    "        rewards = self.classifier(pooled)              # [B, 1]\n",
    "\n",
    "        # return SequenceClassifierOutput with logits=reward\n",
    "        if not return_dict:\n",
    "            return (rewards,)\n",
    "        return SequenceClassifierOutput(logits=rewards)\n",
    "\n",
    "    def save_pretrained(self, save_directory, **kwargs):\n",
    "        os.makedirs(save_directory, exist_ok=True)\n",
    "        torch.save(self.lm_model.lm_head.state_dict(), os.path.join(save_directory, \"lm_head.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621ab080",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "max_length = 512\n",
    "\n",
    "dataset = load_dataset(path ='Dahoas/rm-static', cache_dir = FILE_PATH)\n",
    "\n",
    "\n",
    "def prep_batch(batch):\n",
    "    chosen = [p + \" \" + c for p, c in zip(batch[\"prompt\"], batch[\"chosen\"])]\n",
    "    rejected = [p + \" \" + r for p, r in zip(batch[\"prompt\"], batch[\"rejected\"])]\n",
    "    chosen_tok = tokenizer(chosen, truncation=True, padding=\"max_length\", max_length=max_length)\n",
    "    rejected_tok = tokenizer(rejected, truncation=True, padding=\"max_length\", max_length=max_length)\n",
    "    return {\n",
    "        \"chosen_input_ids\": chosen_tok[\"input_ids\"],\n",
    "        \"chosen_attention_mask\": chosen_tok[\"attention_mask\"],\n",
    "        \"rejected_input_ids\": rejected_tok[\"input_ids\"],\n",
    "        \"rejected_attention_mask\": rejected_tok[\"attention_mask\"],\n",
    "    }\n",
    "\n",
    "tokenized = dataset.map(prep_batch, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "def simple_reward_collator(batch):\n",
    "    # batch: list of dicts (from dataset)\n",
    "    # assume lists of ints for each key\n",
    "    chosen_ids = torch.tensor([ex[\"chosen_input_ids\"] for ex in batch], dtype=torch.long)\n",
    "    chosen_mask = torch.tensor([ex[\"chosen_attention_mask\"] for ex in batch], dtype=torch.long)\n",
    "    rejected_ids = torch.tensor([ex[\"rejected_input_ids\"] for ex in batch], dtype=torch.long)\n",
    "    rejected_mask = torch.tensor([ex[\"rejected_attention_mask\"] for ex in batch], dtype=torch.long)\n",
    "\n",
    "    return {\n",
    "        \"chosen_input_ids\": chosen_ids,\n",
    "        \"chosen_attention_mask\": chosen_mask,\n",
    "        \"rejected_input_ids\": rejected_ids,\n",
    "        \"rejected_attention_mask\": rejected_mask,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33454f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenized[\"train\"].column_names)\n",
    "# must include the four keys used by collator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397eb7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(BASE_MODEL, num_labels=1, cache_dir = FILE_PATH)\n",
    "\n",
    "# print(\"config is \", config)\n",
    "\n",
    "device_str = 'cpu'\n",
    "conv_model = ConvertedModel(config).to(device_str)\n",
    "\n",
    "# use trainer class /  reward model in this \n",
    "from transformers import HfArgumentParser\n",
    "from datasets import load_dataset\n",
    "from trl import (\n",
    "    ModelConfig,\n",
    "    RewardConfig,\n",
    "    RewardTrainer,\n",
    "    ScriptArguments,\n",
    "    get_kbit_device_map,\n",
    "    get_peft_config,\n",
    "    get_quantization_config,\n",
    "    setup_chat_format,\n",
    ")\n",
    "\n",
    "\n",
    "# dataset.to(device_str)\n",
    "\n",
    "\n",
    "reward_args = RewardConfig(\n",
    "    output_dir=os.path.join(FILE_PATH, \"reward_outputs\"),   # checkpoint + logs dir\n",
    "    logging_dir=os.path.join(FILE_PATH, \"logs\"),            # local tensorboard logs\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=2,\n",
    "    num_train_epochs=10,\n",
    "    logging_steps=10,\n",
    "    gradient_checkpointing=False, \n",
    "    learning_rate = 0.0000001,\n",
    "    max_grad_norm = 1.0,\n",
    "\n",
    "    # Precision\n",
    "    fp16=False,          # disable mixed precision\n",
    "    bf16=False,\n",
    "\n",
    "    # Checkpoint saving\n",
    "    save_strategy=\"steps\",   # instead of \"epoch\"\n",
    "    save_steps=5,            # save every 5 steps\n",
    "    save_total_limit=2,      # keep only last 2 checkpoints\n",
    "\n",
    "    # W&B integration\n",
    "    report_to=[],       # logs training metrics to wandb\n",
    "    run_name=\"reward_model_gemma_linear_head\"  # nice display name in wandb\n",
    ")\n",
    "\n",
    "trainer = RewardTrainer(\n",
    "    model=conv_model,\n",
    "    processing_class=None,\n",
    "    data_collator=simple_reward_collator,\n",
    "    args=reward_args,\n",
    "    train_dataset=tokenized['train'], \n",
    "    eval_dataset = tokenized['test'],\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Starting the trainer module !!\")\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be8ec23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95833004",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86034727",
   "metadata": {},
   "source": [
    "debuggings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aef449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "conv_model = ConvertedModel(config).to('mps')\n",
    "\n",
    "\n",
    "for n, p in conv_model.named_parameters():\n",
    "    print(n, p.device, p.dtype, torch.isfinite(p).all().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c65038",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model.eval()\n",
    "ids = torch.tensor([tokenizer[\"train\"][\"chosen_input_ids\"][0]], device='mps')\n",
    "mask = torch.tensor([tokenizer[\"train\"][\"chosen_attention_mask\"][0]], device='mps')\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = conv_model(input_ids=ids, attention_mask=mask, return_dict=True)\n",
    "    print(\"logits:\", out.logits, \"finite:\", torch.isfinite(out.logits).all().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c667155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ae027c1",
   "metadata": {},
   "source": [
    "chatgpt starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951b021b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check logits shape: torch.Size([1, 1]) finite: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohitdulani/Desktop/personal/rlhf/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "You're using a GemmaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training — trainer.train() ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='23820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   49/23820 02:16 < 19:12:46, 0.34 it/s, Epoch 0.02/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.965100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.016600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 133\u001b[39m\n\u001b[32m    124\u001b[39m trainer = RewardTrainer(\n\u001b[32m    125\u001b[39m     model=conv_model,\n\u001b[32m    126\u001b[39m     processing_class=tokenizer,   \u001b[38;5;66;03m# let TRL create input_ids_chosen / input_ids_rejected\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    129\u001b[39m     eval_dataset=dataset[\u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    130\u001b[39m )\n\u001b[32m    132\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting training — trainer.train() ...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/personal/rlhf/.venv/lib/python3.13/site-packages/transformers/trainer.py:2328\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2326\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2327\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2333\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/personal/rlhf/.venv/lib/python3.13/site-packages/transformers/trainer.py:2677\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2671\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m   2672\u001b[39m     tr_loss_step = \u001b[38;5;28mself\u001b[39m.training_step(model, inputs, num_items_in_batch)\n\u001b[32m   2674\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2675\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2676\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m-> \u001b[39m\u001b[32m2677\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   2678\u001b[39m ):\n\u001b[32m   2679\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2680\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n\u001b[32m   2681\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "socket.send() raised exception.\n",
      "socket.send() raised exception.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Single runnable cell — minimal, targeted fixes only (copy-paste)\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoConfig,\n",
    "    PreTrainedModel,\n",
    ")\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from trl import RewardConfig, RewardTrainer\n",
    "\n",
    "# ------------------ USER-CHOICE (preserved) ------------------\n",
    "BASE_MODEL = \"google/gemma-3-270m-it\"\n",
    "\n",
    "# keep your FILE_PATH variable as-is in your environment\n",
    "# if it's not defined, set a sensible default (uncomment next line)\n",
    "# FILE_PATH = \"./models\"\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# 1) tokenizer (used by RewardTrainer as processing_class)\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, cache_dir=FILE_PATH)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# 2) ConvertedModel: PreTrainedModel wrapper that uses frozen causal LM backbone\n",
    "class ConvertedModel(PreTrainedModel):\n",
    "    def __init__(self, config, **kwargs):\n",
    "        super().__init__(config)\n",
    "        # preserve your supplied model name if provided; else fall back to config\n",
    "        self.model_name = kwargs.get(\"model\", getattr(config, \"name_or_path\", BASE_MODEL))\n",
    "        # reward head => single scalar\n",
    "        self.num_labels = kwargs.get(\"num_labels\", getattr(config, \"num_labels\", 1))\n",
    "\n",
    "        # load frozen LM backbone\n",
    "        self.lm_model = AutoModelForCausalLM.from_pretrained(self.model_name, cache_dir=FILE_PATH)\n",
    "        for p in self.lm_model.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        # replace lm_head with scalar reward head — do NOT pass device here\n",
    "        in_features = self.lm_model.lm_head.in_features\n",
    "        self.lm_model.lm_head = nn.Linear(in_features, 1)\n",
    "        self.classifier = self.lm_model.lm_head\n",
    "        for p in self.classifier.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, return_dict: bool = True, **kwargs):\n",
    "        # pass through LM body\n",
    "        lm_out = self.lm_model.model(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
    "        last_hidden = lm_out.last_hidden_state        # [B, L, H]\n",
    "        pooled = last_hidden[:, -1, :]                # last token pooling -> [B, H]\n",
    "        rewards = self.classifier(pooled)             # [B, 1]\n",
    "        if not return_dict:\n",
    "            return (rewards,)\n",
    "        return SequenceClassifierOutput(logits=rewards)\n",
    "\n",
    "    # lightweight saving: store only head weights (as you requested earlier)\n",
    "    def save_pretrained(self, save_directory, **kwargs):\n",
    "        os.makedirs(save_directory, exist_ok=True)\n",
    "        torch.save(self.classifier.state_dict(), os.path.join(save_directory, \"lm_head.pt\"))\n",
    "\n",
    "# 3) build model from config and move to device (CPU by default)\n",
    "config = AutoConfig.from_pretrained(BASE_MODEL, num_labels=1, cache_dir=FILE_PATH)\n",
    "conv_model = ConvertedModel(config, model=BASE_MODEL, num_labels=1)\n",
    "\n",
    "device = torch.device(\"mps\")  # change to \"cuda\" if you have CUDA and want to use it\n",
    "conv_model.to(device)\n",
    "\n",
    "# 4) load raw preference dataset (let RewardTrainer handle tokenization)\n",
    "dataset = load_dataset(\"Dahoas/rm-static\", cache_dir=FILE_PATH)\n",
    "\n",
    "# 5) reward/trainer args (keeps your preferences)\n",
    "reward_args = RewardConfig(\n",
    "    output_dir=os.path.join(FILE_PATH, \"reward_outputs\"),\n",
    "    logging_dir=os.path.join(FILE_PATH, \"logs\"),\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=32,\n",
    "    num_train_epochs=10,\n",
    "    logging_steps=20,\n",
    "    gradient_checkpointing=False,\n",
    "    learning_rate=1e-5,\n",
    "    max_grad_norm=1.0,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=5,\n",
    "    save_total_limit=2,\n",
    "    report_to=['wandb'],   # no live wandb streaming\n",
    "    run_name=\"reward_model_gemma_linear_head\",\n",
    "    max_length=512,\n",
    "    dataset_num_proc=1,\n",
    ")\n",
    "\n",
    "# 6) sanity check: forward with tokenizer on a single example (ensure finite logits)\n",
    "conv_model.eval()\n",
    "sample = dataset[\"train\"][0]\n",
    "# create one prompt+response string (prompt+chosen) to check tokenization + forward\n",
    "chosen_text = sample[\"prompt\"] + \" \" + sample[\"chosen\"]\n",
    "tok = tokenizer(chosen_text, truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\")\n",
    "inp_ids = tok[\"input_ids\"].to(device)\n",
    "attn = tok[\"attention_mask\"].to(device)\n",
    "with torch.no_grad():\n",
    "    out = conv_model(input_ids=inp_ids, attention_mask=attn, return_dict=True).logits\n",
    "print(\"Sanity check logits shape:\", out.shape, \"finite:\", torch.isfinite(out).all().item())\n",
    "\n",
    "# If logits are not finite, reinitialize head and re-run sanity check\n",
    "if not torch.isfinite(out).all().item():\n",
    "    print(\"Reinitializing head (non-finite detected).\")\n",
    "    in_f = conv_model.classifier.in_features\n",
    "    conv_model.classifier = nn.Linear(in_f, 1)\n",
    "    nn.init.normal_(conv_model.classifier.weight, std=0.02)\n",
    "    nn.init.zeros_(conv_model.classifier.bias)\n",
    "    for p in conv_model.classifier.parameters(): p.requires_grad = True\n",
    "    conv_model.to(device)\n",
    "    with torch.no_grad():\n",
    "        out = conv_model(input_ids=inp_ids, attention_mask=attn, return_dict=True).logits\n",
    "    print(\"After reinit finite:\", torch.isfinite(out).all().item())\n",
    "\n",
    "# 7) instantiate RewardTrainer and run training (let TRL do tokenization)\n",
    "trainer = RewardTrainer(\n",
    "    model=conv_model,\n",
    "    processing_class=tokenizer,   # let TRL create input_ids_chosen / input_ids_rejected\n",
    "    args=reward_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    ")\n",
    "\n",
    "print(\"Starting training — trainer.train() ...\")\n",
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
