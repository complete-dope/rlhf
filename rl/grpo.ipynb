{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77ba951c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mohit/Desktop/mdesktop/rlhf\n"
     ]
    }
   ],
   "source": [
    "# lets now self create the model and see what actually works \n",
    "'''\n",
    "Preference / Reward model \n",
    "Here it learns to reward the \n",
    "\n",
    "** Dataset ** \n",
    "\n",
    "Prompt : Why is the color of sky blue ?\n",
    "Chosen : Its because of the scattering of blue wavelength by air molecules \n",
    "Rejected : Because sky likes blue color\n",
    "\n",
    "\n",
    "The reward model, is a linear layer at top, that learn to output whether this response is good or not \n",
    "\n",
    "Input1 to model : {Prompt + Chosen} ,  Output1 : 1  \n",
    "Input2 to model : {Prompt + Rejected}  , Output2: 0 \n",
    "\n",
    "\n",
    "Here the model learns to pick up a good response !\n",
    "\n",
    "This is the logic that happens in PPO loop ! So there is nothing as seperate training for a PPO model directly just use this as a Value head  \n",
    "'''\n",
    "\n",
    "# Single runnable cell — minimal, targeted fixes only (copy-paste)\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoConfig,\n",
    "    PreTrainedModel,\n",
    "    GenerationConfig\n",
    ")\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from trl import AutoModelForCausalLMWithValueHead\n",
    "from transformers.modeling_outputs import ModelOutput\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# ------------------ USER-CHOICE (preserved) ------------------\n",
    "BASE_MODEL = \"HuggingFaceTB/SmolLM2-135M-Instruct\"\n",
    "DATASET_LINK = \"Dahoas/rm-static\"\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "\n",
    "import os \n",
    "FILE_PATH = os.path.dirname(os.path.abspath(\"\"))\n",
    "print(FILE_PATH)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcb24bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(BASE_MODEL , cache_dir = FILE_PATH)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, cache_dir = FILE_PATH)\n",
    "\n",
    "dataset = load_dataset(DATASET_LINK, split=\"train[:20]\", cache_dir=FILE_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b95c7426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.bos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d5bf3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': '<|im_start|>\\n\\nHuman: Can you describe the steps to clean fingerprints and smudges from a laptop screen\\n\\nAssistant: Yes, certainly. To clean your screen, you first need to use a microfiber cloth or soft, damp cloth to gently wipe down the surface of the screen. Next, you’ll want to grab a soft, lint-free, microfiber cleaning cloth and gently rub it back and forth across the screen to remove fingerprints and smudges.\\n\\nHuman: Can I spray isopropyl alcohol onto the cloth and clean it that way?\\n\\nAssistant:', 'response': ' Yes, you can do that to help the cloth pick up even more dirt from the screen. Be sure to always use a clean, soft cloth, not a piece of scratchy, roughened, or textured material, and make sure it’s lint-free.', 'chosen': ' Yes, you can do that to help the cloth pick up even more dirt from the screen. Be sure to always use a clean, soft cloth, not a piece of scratchy, roughened, or textured material, and make sure it’s lint-free.', 'rejected': ' Yes, you can spray it directly onto the cloth.', 'input_ids': [1, 198, 198, 14917, 42, 1978, 346, 5125, 260, 3301, 288, 2577, 34957, 284, 865, 413, 2519, 429, 253, 17066, 5078, 198, 198, 9519, 9531, 42, 9230, 28, 5508, 30, 1626, 2577, 469, 5078, 28, 346, 808, 737, 288, 722, 253, 32907, 8550, 11244, 355, 2375, 28, 14456, 11244, 288, 9014, 24613, 1187, 260, 2376, 282, 260, 5078, 30, 9528, 28, 346, 417, 764, 1277, 288, 9399, 253, 2375, 28, 46478, 29, 5725, 28, 32907, 8550, 7811, 11244, 284, 9014, 6460, 357, 1056, 284, 7146, 1699, 260, 5078, 288, 4351, 34957, 284, 865, 413, 2519, 30, 198, 198, 14917, 42, 1978, 339, 9779, 314, 371, 11899, 92, 4657, 4581, 260, 11244, 284, 2577, 357, 338, 970, 47, 198, 198, 9519, 9531, 42], 'resp_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "def prepare_dataset(example):\n",
    "    prompt = tokenizer.bos_token + example['prompt']\n",
    "    example['prompt'] = prompt\n",
    "    tokenized_example =  tokenizer(prompt)\n",
    "    input_ids = tokenized_example.input_ids\n",
    "    attention_mask = tokenized_example.attention_mask\n",
    "    mask = torch.tensor([1] * len(input_ids))\n",
    "\n",
    "    return {\n",
    "        'input_ids':input_ids, \n",
    "        'resp_mask': mask, \n",
    "        'attention_mask':mask\n",
    "    }\n",
    "\n",
    "dataset = dataset.map(prepare_dataset)\n",
    "\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73ce6570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': '<|im_start|>\\n\\nHuman: Can you describe the steps to clean fingerprints and smudges from a laptop screen\\n\\nAssistant: Yes, certainly. To clean your screen, you first need to use a microfiber cloth or soft, damp cloth to gently wipe down the surface of the screen. Next, you’ll want to grab a soft, lint-free, microfiber cleaning cloth and gently rub it back and forth across the screen to remove fingerprints and smudges.\\n\\nHuman: Can I spray isopropyl alcohol onto the cloth and clean it that way?\\n\\nAssistant:',\n",
       " 'response': ' Yes, you can do that to help the cloth pick up even more dirt from the screen. Be sure to always use a clean, soft cloth, not a piece of scratchy, roughened, or textured material, and make sure it’s lint-free.',\n",
       " 'chosen': ' Yes, you can do that to help the cloth pick up even more dirt from the screen. Be sure to always use a clean, soft cloth, not a piece of scratchy, roughened, or textured material, and make sure it’s lint-free.',\n",
       " 'rejected': ' Yes, you can spray it directly onto the cloth.',\n",
       " 'input_ids': [1,\n",
       "  198,\n",
       "  198,\n",
       "  14917,\n",
       "  42,\n",
       "  1978,\n",
       "  346,\n",
       "  5125,\n",
       "  260,\n",
       "  3301,\n",
       "  288,\n",
       "  2577,\n",
       "  34957,\n",
       "  284,\n",
       "  865,\n",
       "  413,\n",
       "  2519,\n",
       "  429,\n",
       "  253,\n",
       "  17066,\n",
       "  5078,\n",
       "  198,\n",
       "  198,\n",
       "  9519,\n",
       "  9531,\n",
       "  42,\n",
       "  9230,\n",
       "  28,\n",
       "  5508,\n",
       "  30,\n",
       "  1626,\n",
       "  2577,\n",
       "  469,\n",
       "  5078,\n",
       "  28,\n",
       "  346,\n",
       "  808,\n",
       "  737,\n",
       "  288,\n",
       "  722,\n",
       "  253,\n",
       "  32907,\n",
       "  8550,\n",
       "  11244,\n",
       "  355,\n",
       "  2375,\n",
       "  28,\n",
       "  14456,\n",
       "  11244,\n",
       "  288,\n",
       "  9014,\n",
       "  24613,\n",
       "  1187,\n",
       "  260,\n",
       "  2376,\n",
       "  282,\n",
       "  260,\n",
       "  5078,\n",
       "  30,\n",
       "  9528,\n",
       "  28,\n",
       "  346,\n",
       "  417,\n",
       "  764,\n",
       "  1277,\n",
       "  288,\n",
       "  9399,\n",
       "  253,\n",
       "  2375,\n",
       "  28,\n",
       "  46478,\n",
       "  29,\n",
       "  5725,\n",
       "  28,\n",
       "  32907,\n",
       "  8550,\n",
       "  7811,\n",
       "  11244,\n",
       "  284,\n",
       "  9014,\n",
       "  6460,\n",
       "  357,\n",
       "  1056,\n",
       "  284,\n",
       "  7146,\n",
       "  1699,\n",
       "  260,\n",
       "  5078,\n",
       "  288,\n",
       "  4351,\n",
       "  34957,\n",
       "  284,\n",
       "  865,\n",
       "  413,\n",
       "  2519,\n",
       "  30,\n",
       "  198,\n",
       "  198,\n",
       "  14917,\n",
       "  42,\n",
       "  1978,\n",
       "  339,\n",
       "  9779,\n",
       "  314,\n",
       "  371,\n",
       "  11899,\n",
       "  92,\n",
       "  4657,\n",
       "  4581,\n",
       "  260,\n",
       "  11244,\n",
       "  284,\n",
       "  2577,\n",
       "  357,\n",
       "  338,\n",
       "  970,\n",
       "  47,\n",
       "  198,\n",
       "  198,\n",
       "  9519,\n",
       "  9531,\n",
       "  42],\n",
       " 'resp_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d63ca5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "logp = None\n",
    "\n",
    "def next_token_prediction_values(logp:torch.Tensor, idx :int ) -> torch.Tensor:\n",
    "    return logp[:, idx, :] # output will be torch tensor \n",
    "\n",
    "# resp_mask this is the response mask that means it tells which parts of the prompt to take in the input and which parts not to take !!\n",
    "def seq_logprob(model , input_ids , attention_mask, resp_mask):\n",
    "    '''\n",
    "    This is the log prob, this is the \n",
    "    '''\n",
    "    \n",
    "    if type(input_ids) is not torch.Tensor:\n",
    "        print(input_ids)\n",
    "        print(type(input_ids))\n",
    "        input_ids = torch.tensor(data = input_ids, dtype = torch.int32)\n",
    "        attention_mask = torch.tensor(data = attention_mask, dtype=torch.int32)\n",
    "\n",
    "    out = model(input_ids = input_ids.unsqueeze(0), attention_mask = attention_mask.unsqueeze(0))\n",
    "    print(\"out logits shape is \", out.logits.shape) # outputs the probability for all the input tokens , the next one will only be from the last one\n",
    "\n",
    "    # In the DPO, I am already passing the input to the model / the output also in the prompt itself ..  \n",
    "    logp = F.log_softmax(out.logits, dim = -1)\n",
    "    print(\"full logp shape is : \", logp.shape) # log outputs for all the next tokens  \n",
    "\n",
    "    # Now I need to find the last one, so we are taking the probability of the whole sequence .. the input + output ( prompt + response) \n",
    "    # global logp\n",
    "    logp = F.log_softmax(out.logits, dim = -1)\n",
    "    print('logp shape is : ' , logp.shape) # 1 x 163 x VS\n",
    "\n",
    "    output_model_prob = []\n",
    "    for i,val in enumerate(resp_mask):\n",
    "        if val == 0: \n",
    "            continue\n",
    "        else:\n",
    "            prob_distribution = next_token_prediction_values(logp, i-1).squeeze(0) # so to get prev one -> 1xVS \n",
    "            correct_token_idx = input_ids[i] # correct / incorrect input idx ..  \n",
    "            val = prob_distribution[correct_token_idx]\n",
    "            print('Token should have been : ', tokenizer.decode([correct_token_idx]), ' The probability I am getting out from this is : ', val.item()) \n",
    "            output_model_prob.append(val)\n",
    "\n",
    "    print(type(output_model_prob))\n",
    "    \n",
    "    return torch.stack(output_model_prob).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b42ba3",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4313c76b",
   "metadata": {},
   "source": [
    "\n",
    "Prompt: 'How to pet my dog?'\n",
    "\n",
    "Answer: \n",
    "\n",
    "token-1 : 'Petting'\n",
    "token-2 : 'your'\n",
    "token-3 : 'dog'\n",
    "token-4 : 'is'\n",
    "token-5 : 'a'\n",
    "token-6 : 'good'\n",
    "token-7 : 'relaxation'\n",
    "... etc \n",
    "\n",
    "\n",
    "\n",
    "output 1 : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b58d1736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:A <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> model is loaded from 'HuggingFaceTB/SmolLM2-135M-Instruct', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoModelForCausalLMWithValueHead(\n",
       "  (pretrained_model): LlamaForCausalLM(\n",
       "    (model): LlamaModel(\n",
       "      (embed_tokens): Embedding(49152, 576, padding_idx=2)\n",
       "      (layers): ModuleList(\n",
       "        (0-29): 30 x LlamaDecoderLayer(\n",
       "          (self_attn): LlamaAttention(\n",
       "            (q_proj): Linear(in_features=576, out_features=576, bias=False)\n",
       "            (k_proj): Linear(in_features=576, out_features=192, bias=False)\n",
       "            (v_proj): Linear(in_features=576, out_features=192, bias=False)\n",
       "            (o_proj): Linear(in_features=576, out_features=576, bias=False)\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (gate_proj): Linear(in_features=576, out_features=1536, bias=False)\n",
       "            (up_proj): Linear(in_features=576, out_features=1536, bias=False)\n",
       "            (down_proj): Linear(in_features=1536, out_features=576, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n",
       "          (post_attention_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n",
       "        )\n",
       "      )\n",
       "      (norm): LlamaRMSNorm((576,), eps=1e-05)\n",
       "      (rotary_emb): LlamaRotaryEmbedding()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=576, out_features=49152, bias=False)\n",
       "  )\n",
       "  (v_head): ValueHead(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (summary): Linear(in_features=576, out_features=1, bias=True)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from transformers import PreTrainedModel\n",
    "\n",
    "# class RewardModel(PreTrained):\n",
    "#     '''\n",
    "#     Ideally this would be a trained model \n",
    "#     '''   \n",
    "from trl import AutoModelForCausalLMWithValueHead\n",
    "reward_model = AutoModelForCausalLMWithValueHead.from_pretrained(BASE_MODEL, cache_dir = FILE_PATH)\n",
    "\n",
    "reward_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c8666a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = 'I am a good boy'\n",
    "ds = tokenizer(vals).input_ids\n",
    "ds = torch.tensor(data = ds).unsqueeze(0).to(DEVICE)\n",
    "a = reward_model.forward(ds)\n",
    "# print(a[1][-1])\n",
    "a[2][:,-1]\n",
    "\n",
    "# tokenizer.decode(*a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a52f62e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.3831, -0.0811,  0.0221,  0.2754, -1.0237]], device='cuda:0',\n",
       "        grad_fn=<SqueezeBackward1>),\n",
       " tensor([-1.0237], device='cuda:0', grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2], a[2][:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56a3bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import GenerationConfig\n",
    "# https://huggingface.co/docs/transformers/en/main_classes/text_generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e6cbcd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5000, -0.5000, -0.5000,  1.5000])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def sampling_outputs(model , data , n=5):\n",
    "    generation_config = GenerationConfig.from_pretrained(BASE_MODEL, cache_dir=FILE_PATH)\n",
    "    \n",
    "    generation_config.max_new_length = 120\n",
    "    generation_config.temperature= 0.5\n",
    "    generation_config.use_cache = False\n",
    "    \n",
    "    input_ids = torch.tensor(data['input_ids']).unsqueeze(0).to(DEVICE)\n",
    "    print('Input ids are : ' , input_ids.device)\n",
    "\n",
    "    outs = []\n",
    "    for _ in range(n):\n",
    "        print('inside the loop !!')\n",
    "        print(\"The input to the model is \" , tokenizer.decode(*input_ids) )\n",
    "        out = model.generate(input_ids , generation_config = generation_config)\n",
    "        generated_output = out[:, input_ids.shape[1]:]\n",
    "\n",
    "        print('model outputs is : ',  generated_output  , generated_output.device)\n",
    "        out = tokenizer.decode(*out) # this is giving the whole input + the output\n",
    "        outs.append(out)\n",
    "\n",
    "    return outs\n",
    "\n",
    "\n",
    "def scoring_outputs(reward_model, outputs):\n",
    "    \n",
    "    if type(outputs) == list:\n",
    "        print(\"Type of outputs is : \", type(outputs), outputs)\n",
    "\n",
    "    rewards = []\n",
    "    for output in outputs: \n",
    "        \n",
    "        tokenized_data = tokenizer(output)\n",
    "        input_ids = tokenized_data.input_ids\n",
    "        attention_mask = tokenized_data.attention_mask\n",
    "        print('The tokenized data is', tokenized_data)\n",
    "        input_ids = torch.tensor(data = input_ids).to(DEVICE).unsqueeze(0)\n",
    "        attention_mask = torch.tensor(data = attention_mask).to(DEVICE).unsqueeze(0)\n",
    "\n",
    "        reward = reward_model.forward(input_ids , attention_mask = attention_mask)\n",
    "        reward = reward[2][:,-1]\n",
    "        rewards.append(reward)\n",
    "\n",
    "    return rewards        \n",
    "    \n",
    "\n",
    "\n",
    "def group_computation(advantages):\n",
    "    '''\n",
    "    This is the GRPO loss,  \n",
    "    '''\n",
    "    advantages = torch.stack(advantages).float()\n",
    "    return  (advantages - advantages.mean()) / advantages.std()\n",
    "\n",
    "\n",
    "data = torch.tensor(data= 1)\n",
    "data2 = torch.tensor(data= 2)\n",
    "reward = [1,2,3,4,45]\n",
    "reward = [data, data, data, data2]\n",
    "\n",
    "print(group_computation(reward))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f889587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grpo_loss(advantages:torch.Tensor, outputs:torch.Tensor, beta, reference_model, data):\n",
    "    '''GRPO loss '''\n",
    "\n",
    "\n",
    "    grp_avg = 1 / advantages.shape[1]\n",
    "    out_avg = 1 / \n",
    "\n",
    "\n",
    "    for idx, advantage in enumerate(advantages):\n",
    "        o_i = outputs[idx].item()\n",
    "        if o_i < 0:\n",
    "            o_i =-1 * o_i\n",
    "\n",
    "        1/o_i\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfad47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "input_ids = torch.tensor(dataset[0]['input_ids']).unsqueeze(0)\n",
    "attention_mask = torch.tensor(dataset[0]['attention_mask']).unsqueeze(0)\n",
    "print(input_ids)\n",
    "outs =model.generate(input_ids)\n",
    "print(outs.shape)\n",
    "\n",
    "print(outs)\n",
    "print(tokenizer.decode(*outs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a498ad85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The models are on :  cuda:0\n",
      "Starting the training loop\n",
      "Input ids are :  cuda:0\n",
      "inside the loop !!\n",
      "The input to the model is  <|im_start|>\n",
      "\n",
      "Human: Can you describe the steps to clean fingerprints and smudges from a laptop screen\n",
      "\n",
      "Assistant: Yes, certainly. To clean your screen, you first need to use a microfiber cloth or soft, damp cloth to gently wipe down the surface of the screen. Next, you’ll want to grab a soft, lint-free, microfiber cleaning cloth and gently rub it back and forth across the screen to remove fingerprints and smudges.\n",
      "\n",
      "Human: Can I spray isopropyl alcohol onto the cloth and clean it that way?\n",
      "\n",
      "Assistant:\n",
      "model outputs is :  tensor([[ 9230,    28, 10556,    30,  1206,   416,   722,   253,  9779, 10765,\n",
      "          4412,   351,   314,   371, 11899,    92,  4657,   288,  2577,   260]],\n",
      "       device='cuda:0') cuda:0\n",
      "inside the loop !!\n",
      "The input to the model is  <|im_start|>\n",
      "\n",
      "Human: Can you describe the steps to clean fingerprints and smudges from a laptop screen\n",
      "\n",
      "Assistant: Yes, certainly. To clean your screen, you first need to use a microfiber cloth or soft, damp cloth to gently wipe down the surface of the screen. Next, you’ll want to grab a soft, lint-free, microfiber cleaning cloth and gently rub it back and forth across the screen to remove fingerprints and smudges.\n",
      "\n",
      "Human: Can I spray isopropyl alcohol onto the cloth and clean it that way?\n",
      "\n",
      "Assistant:\n",
      "model outputs is :  tensor([[ 9230,    28, 10556,    30,  1206,   416,   722,   253,  9779, 10765,\n",
      "          4412,   351,   314,   371, 11899,    92,  4657,   288,  2577,   260]],\n",
      "       device='cuda:0') cuda:0\n",
      "inside the loop !!\n",
      "The input to the model is  <|im_start|>\n",
      "\n",
      "Human: Can you describe the steps to clean fingerprints and smudges from a laptop screen\n",
      "\n",
      "Assistant: Yes, certainly. To clean your screen, you first need to use a microfiber cloth or soft, damp cloth to gently wipe down the surface of the screen. Next, you’ll want to grab a soft, lint-free, microfiber cleaning cloth and gently rub it back and forth across the screen to remove fingerprints and smudges.\n",
      "\n",
      "Human: Can I spray isopropyl alcohol onto the cloth and clean it that way?\n",
      "\n",
      "Assistant:\n",
      "model outputs is :  tensor([[ 9230,    28, 10556,    30,  1206,   416,   722,   253,  9779, 10765,\n",
      "          4412,   351,   314,   371, 11899,    92,  4657,   288,  2577,   260]],\n",
      "       device='cuda:0') cuda:0\n",
      "inside the loop !!\n",
      "The input to the model is  <|im_start|>\n",
      "\n",
      "Human: Can you describe the steps to clean fingerprints and smudges from a laptop screen\n",
      "\n",
      "Assistant: Yes, certainly. To clean your screen, you first need to use a microfiber cloth or soft, damp cloth to gently wipe down the surface of the screen. Next, you’ll want to grab a soft, lint-free, microfiber cleaning cloth and gently rub it back and forth across the screen to remove fingerprints and smudges.\n",
      "\n",
      "Human: Can I spray isopropyl alcohol onto the cloth and clean it that way?\n",
      "\n",
      "Assistant:\n",
      "model outputs is :  tensor([[ 9230,    28, 10556,    30,  1206,   416,   722,   253,  9779, 10765,\n",
      "          4412,   351,   314,   371, 11899,    92,  4657,   288,  2577,   260]],\n",
      "       device='cuda:0') cuda:0\n",
      "sampled the outputs ['<|im_start|>\\n\\nHuman: Can you describe the steps to clean fingerprints and smudges from a laptop screen\\n\\nAssistant: Yes, certainly. To clean your screen, you first need to use a microfiber cloth or soft, damp cloth to gently wipe down the surface of the screen. Next, you’ll want to grab a soft, lint-free, microfiber cleaning cloth and gently rub it back and forth across the screen to remove fingerprints and smudges.\\n\\nHuman: Can I spray isopropyl alcohol onto the cloth and clean it that way?\\n\\nAssistant: Yes, absolutely. You can use a spray bottle filled with isopropyl alcohol to clean the', '<|im_start|>\\n\\nHuman: Can you describe the steps to clean fingerprints and smudges from a laptop screen\\n\\nAssistant: Yes, certainly. To clean your screen, you first need to use a microfiber cloth or soft, damp cloth to gently wipe down the surface of the screen. Next, you’ll want to grab a soft, lint-free, microfiber cleaning cloth and gently rub it back and forth across the screen to remove fingerprints and smudges.\\n\\nHuman: Can I spray isopropyl alcohol onto the cloth and clean it that way?\\n\\nAssistant: Yes, absolutely. You can use a spray bottle filled with isopropyl alcohol to clean the', '<|im_start|>\\n\\nHuman: Can you describe the steps to clean fingerprints and smudges from a laptop screen\\n\\nAssistant: Yes, certainly. To clean your screen, you first need to use a microfiber cloth or soft, damp cloth to gently wipe down the surface of the screen. Next, you’ll want to grab a soft, lint-free, microfiber cleaning cloth and gently rub it back and forth across the screen to remove fingerprints and smudges.\\n\\nHuman: Can I spray isopropyl alcohol onto the cloth and clean it that way?\\n\\nAssistant: Yes, absolutely. You can use a spray bottle filled with isopropyl alcohol to clean the', '<|im_start|>\\n\\nHuman: Can you describe the steps to clean fingerprints and smudges from a laptop screen\\n\\nAssistant: Yes, certainly. To clean your screen, you first need to use a microfiber cloth or soft, damp cloth to gently wipe down the surface of the screen. Next, you’ll want to grab a soft, lint-free, microfiber cleaning cloth and gently rub it back and forth across the screen to remove fingerprints and smudges.\\n\\nHuman: Can I spray isopropyl alcohol onto the cloth and clean it that way?\\n\\nAssistant: Yes, absolutely. You can use a spray bottle filled with isopropyl alcohol to clean the']\n",
      "4 ['<|im_start|>\\n\\nHuman: Can you describe the steps to clean fingerprints and smudges from a laptop screen\\n\\nAssistant: Yes, certainly. To clean your screen, you first need to use a microfiber cloth or soft, damp cloth to gently wipe down the surface of the screen. Next, you’ll want to grab a soft, lint-free, microfiber cleaning cloth and gently rub it back and forth across the screen to remove fingerprints and smudges.\\n\\nHuman: Can I spray isopropyl alcohol onto the cloth and clean it that way?\\n\\nAssistant: Yes, absolutely. You can use a spray bottle filled with isopropyl alcohol to clean the', '<|im_start|>\\n\\nHuman: Can you describe the steps to clean fingerprints and smudges from a laptop screen\\n\\nAssistant: Yes, certainly. To clean your screen, you first need to use a microfiber cloth or soft, damp cloth to gently wipe down the surface of the screen. Next, you’ll want to grab a soft, lint-free, microfiber cleaning cloth and gently rub it back and forth across the screen to remove fingerprints and smudges.\\n\\nHuman: Can I spray isopropyl alcohol onto the cloth and clean it that way?\\n\\nAssistant: Yes, absolutely. You can use a spray bottle filled with isopropyl alcohol to clean the', '<|im_start|>\\n\\nHuman: Can you describe the steps to clean fingerprints and smudges from a laptop screen\\n\\nAssistant: Yes, certainly. To clean your screen, you first need to use a microfiber cloth or soft, damp cloth to gently wipe down the surface of the screen. Next, you’ll want to grab a soft, lint-free, microfiber cleaning cloth and gently rub it back and forth across the screen to remove fingerprints and smudges.\\n\\nHuman: Can I spray isopropyl alcohol onto the cloth and clean it that way?\\n\\nAssistant: Yes, absolutely. You can use a spray bottle filled with isopropyl alcohol to clean the', '<|im_start|>\\n\\nHuman: Can you describe the steps to clean fingerprints and smudges from a laptop screen\\n\\nAssistant: Yes, certainly. To clean your screen, you first need to use a microfiber cloth or soft, damp cloth to gently wipe down the surface of the screen. Next, you’ll want to grab a soft, lint-free, microfiber cleaning cloth and gently rub it back and forth across the screen to remove fingerprints and smudges.\\n\\nHuman: Can I spray isopropyl alcohol onto the cloth and clean it that way?\\n\\nAssistant: Yes, absolutely. You can use a spray bottle filled with isopropyl alcohol to clean the']\n",
      "Type of outputs is :  <class 'list'> ['<|im_start|>\\n\\nHuman: Can you describe the steps to clean fingerprints and smudges from a laptop screen\\n\\nAssistant: Yes, certainly. To clean your screen, you first need to use a microfiber cloth or soft, damp cloth to gently wipe down the surface of the screen. Next, you’ll want to grab a soft, lint-free, microfiber cleaning cloth and gently rub it back and forth across the screen to remove fingerprints and smudges.\\n\\nHuman: Can I spray isopropyl alcohol onto the cloth and clean it that way?\\n\\nAssistant: Yes, absolutely. You can use a spray bottle filled with isopropyl alcohol to clean the', '<|im_start|>\\n\\nHuman: Can you describe the steps to clean fingerprints and smudges from a laptop screen\\n\\nAssistant: Yes, certainly. To clean your screen, you first need to use a microfiber cloth or soft, damp cloth to gently wipe down the surface of the screen. Next, you’ll want to grab a soft, lint-free, microfiber cleaning cloth and gently rub it back and forth across the screen to remove fingerprints and smudges.\\n\\nHuman: Can I spray isopropyl alcohol onto the cloth and clean it that way?\\n\\nAssistant: Yes, absolutely. You can use a spray bottle filled with isopropyl alcohol to clean the', '<|im_start|>\\n\\nHuman: Can you describe the steps to clean fingerprints and smudges from a laptop screen\\n\\nAssistant: Yes, certainly. To clean your screen, you first need to use a microfiber cloth or soft, damp cloth to gently wipe down the surface of the screen. Next, you’ll want to grab a soft, lint-free, microfiber cleaning cloth and gently rub it back and forth across the screen to remove fingerprints and smudges.\\n\\nHuman: Can I spray isopropyl alcohol onto the cloth and clean it that way?\\n\\nAssistant: Yes, absolutely. You can use a spray bottle filled with isopropyl alcohol to clean the', '<|im_start|>\\n\\nHuman: Can you describe the steps to clean fingerprints and smudges from a laptop screen\\n\\nAssistant: Yes, certainly. To clean your screen, you first need to use a microfiber cloth or soft, damp cloth to gently wipe down the surface of the screen. Next, you’ll want to grab a soft, lint-free, microfiber cleaning cloth and gently rub it back and forth across the screen to remove fingerprints and smudges.\\n\\nHuman: Can I spray isopropyl alcohol onto the cloth and clean it that way?\\n\\nAssistant: Yes, absolutely. You can use a spray bottle filled with isopropyl alcohol to clean the']\n",
      "The tokenized data is {'input_ids': [1, 198, 198, 14917, 42, 1978, 346, 5125, 260, 3301, 288, 2577, 34957, 284, 865, 413, 2519, 429, 253, 17066, 5078, 198, 198, 9519, 9531, 42, 9230, 28, 5508, 30, 1626, 2577, 469, 5078, 28, 346, 808, 737, 288, 722, 253, 32907, 8550, 11244, 355, 2375, 28, 14456, 11244, 288, 9014, 24613, 1187, 260, 2376, 282, 260, 5078, 30, 9528, 28, 346, 417, 764, 1277, 288, 9399, 253, 2375, 28, 46478, 29, 5725, 28, 32907, 8550, 7811, 11244, 284, 9014, 6460, 357, 1056, 284, 7146, 1699, 260, 5078, 288, 4351, 34957, 284, 865, 413, 2519, 30, 198, 198, 14917, 42, 1978, 339, 9779, 314, 371, 11899, 92, 4657, 4581, 260, 11244, 284, 2577, 357, 338, 970, 47, 198, 198, 9519, 9531, 42, 9230, 28, 10556, 30, 1206, 416, 722, 253, 9779, 10765, 4412, 351, 314, 371, 11899, 92, 4657, 288, 2577, 260], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "The tokenized data is {'input_ids': [1, 198, 198, 14917, 42, 1978, 346, 5125, 260, 3301, 288, 2577, 34957, 284, 865, 413, 2519, 429, 253, 17066, 5078, 198, 198, 9519, 9531, 42, 9230, 28, 5508, 30, 1626, 2577, 469, 5078, 28, 346, 808, 737, 288, 722, 253, 32907, 8550, 11244, 355, 2375, 28, 14456, 11244, 288, 9014, 24613, 1187, 260, 2376, 282, 260, 5078, 30, 9528, 28, 346, 417, 764, 1277, 288, 9399, 253, 2375, 28, 46478, 29, 5725, 28, 32907, 8550, 7811, 11244, 284, 9014, 6460, 357, 1056, 284, 7146, 1699, 260, 5078, 288, 4351, 34957, 284, 865, 413, 2519, 30, 198, 198, 14917, 42, 1978, 339, 9779, 314, 371, 11899, 92, 4657, 4581, 260, 11244, 284, 2577, 357, 338, 970, 47, 198, 198, 9519, 9531, 42, 9230, 28, 10556, 30, 1206, 416, 722, 253, 9779, 10765, 4412, 351, 314, 371, 11899, 92, 4657, 288, 2577, 260], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "The tokenized data is {'input_ids': [1, 198, 198, 14917, 42, 1978, 346, 5125, 260, 3301, 288, 2577, 34957, 284, 865, 413, 2519, 429, 253, 17066, 5078, 198, 198, 9519, 9531, 42, 9230, 28, 5508, 30, 1626, 2577, 469, 5078, 28, 346, 808, 737, 288, 722, 253, 32907, 8550, 11244, 355, 2375, 28, 14456, 11244, 288, 9014, 24613, 1187, 260, 2376, 282, 260, 5078, 30, 9528, 28, 346, 417, 764, 1277, 288, 9399, 253, 2375, 28, 46478, 29, 5725, 28, 32907, 8550, 7811, 11244, 284, 9014, 6460, 357, 1056, 284, 7146, 1699, 260, 5078, 288, 4351, 34957, 284, 865, 413, 2519, 30, 198, 198, 14917, 42, 1978, 339, 9779, 314, 371, 11899, 92, 4657, 4581, 260, 11244, 284, 2577, 357, 338, 970, 47, 198, 198, 9519, 9531, 42, 9230, 28, 10556, 30, 1206, 416, 722, 253, 9779, 10765, 4412, 351, 314, 371, 11899, 92, 4657, 288, 2577, 260], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "The tokenized data is {'input_ids': [1, 198, 198, 14917, 42, 1978, 346, 5125, 260, 3301, 288, 2577, 34957, 284, 865, 413, 2519, 429, 253, 17066, 5078, 198, 198, 9519, 9531, 42, 9230, 28, 5508, 30, 1626, 2577, 469, 5078, 28, 346, 808, 737, 288, 722, 253, 32907, 8550, 11244, 355, 2375, 28, 14456, 11244, 288, 9014, 24613, 1187, 260, 2376, 282, 260, 5078, 30, 9528, 28, 346, 417, 764, 1277, 288, 9399, 253, 2375, 28, 46478, 29, 5725, 28, 32907, 8550, 7811, 11244, 284, 9014, 6460, 357, 1056, 284, 7146, 1699, 260, 5078, 288, 4351, 34957, 284, 865, 413, 2519, 30, 198, 198, 14917, 42, 1978, 339, 9779, 314, 371, 11899, 92, 4657, 4581, 260, 11244, 284, 2577, 357, 338, 970, 47, 198, 198, 9519, 9531, 42, 9230, 28, 10556, 30, 1206, 416, 722, 253, 9779, 10765, 4412, 351, 314, 371, 11899, 92, 4657, 288, 2577, 260], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "rewards are :  <class 'list'> [tensor([-0.3493], device='cuda:0', grad_fn=<SelectBackward0>), tensor([-0.7657], device='cuda:0', grad_fn=<SelectBackward0>), tensor([-0.6238], device='cuda:0', grad_fn=<SelectBackward0>), tensor([0.2184], device='cuda:0', grad_fn=<SelectBackward0>)]\n",
      "Advantages in this are :  tensor(-0.8742, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import gc \n",
    "gc.collect()\n",
    "\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "#model definition \n",
    "policy_model = model\n",
    "reference_model = copy.deepcopy(model).eval()\n",
    "reward_model = reward_model\n",
    "\n",
    "for param in reference_model.parameters():\n",
    "    param.requires_grad = False\n",
    "    param.grad = None\n",
    "\n",
    "optim = torch.optim.AdamW(policy_model.parameters(), lr = 5e-8)\n",
    "\n",
    "# dataset = dataset.map(tokenizer_mapping)\n",
    "device = 'cuda'\n",
    "policy_model = policy_model.to(device)\n",
    "reference_model = reference_model.to(device) \n",
    "reward_model = reward_model.to(device)\n",
    "# dataset = dataset.to(device)\n",
    "\n",
    "print(\"The models are on : \", policy_model.device)\n",
    "\n",
    "outputs = None\n",
    "\n",
    "def training_loop(epochs = 1): \n",
    "    global outputs\n",
    "    print('Starting the training loop')\n",
    "    for idx, data in enumerate(dataset):\n",
    "\n",
    "        # optim.zero_grad() # we dont like accumulation !! \n",
    "        \n",
    "        outputs = sampling_outputs(policy_model, data, n=4)\n",
    "\n",
    "        print('sampled the outputs', outputs )\n",
    "        if type(outputs) == list: \n",
    "            print(len(outputs), outputs)\n",
    "                \n",
    "        rewards = scoring_outputs(reward_model, outputs)\n",
    "\n",
    "        print('rewards are : ', type(rewards), rewards)\n",
    "        assert len(outputs) == len(rewards) , \"The shape mismatch should not occur\"\n",
    "        advantages = group_computation(rewards)\n",
    "\n",
    "        print(\"Advantages in this are : \", advantages)\n",
    "\n",
    "        # Get the final advantages here !! \n",
    "\n",
    "\n",
    "        # loss function implementation !! from : https://arxiv.org/pdf/2402.03300\n",
    "\n",
    "        loss = grpo_loss(advantages , outputs , data)\n",
    "        \n",
    "\n",
    "        break\n",
    "\n",
    "training_loop(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1069cfa0",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/2402.03300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22e97c31",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43moutputs\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'outputs' is not defined"
     ]
    }
   ],
   "source": [
    "outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
